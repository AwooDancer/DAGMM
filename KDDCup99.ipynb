{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDDCup99 10%Data Evaluation\n",
    "- Import KDDCup99 10%data from network and check performance of anomaly detection.\n",
    "- To execute this notebook, need python(3.6), tensorflow, pandas, numpy, sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from dagmm import DAGMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"http://kdd.ics.uci.edu/databases/kddcup99\"\n",
    "\n",
    "# KDDCup 10% Data\n",
    "url_data = f\"{url_base}/kddcup.data_10_percent.gz\"\n",
    "# info data (column names, col types)\n",
    "url_info = f\"{url_base}/kddcup.names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import info data\n",
    "df_info = pd.read_csv(url_info, sep=\":\", skiprows=1, index_col=False, names=[\"colname\", \"type\"])\n",
    "colnames = df_info.colname.values\n",
    "coltypes = np.where(df_info[\"type\"].str.contains(\"continuous\"), \"float\", \"str\")\n",
    "colnames = np.append(colnames, [\"status\"])\n",
    "coltypes = np.append(coltypes, [\"str\"])\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv(url_data, names=colnames, index_col=False,\n",
    "                 dtype=dict(zip(colnames, coltypes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumminize\n",
    "X = pd.get_dummies(df.iloc[:,:-1]).values\n",
    "\n",
    "# Create Traget Flag\n",
    "# Anomaly data when status is normal, Otherwise, Not anomaly.\n",
    "y = np.where(df.status == \"normal.\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=123)\n",
    "X_train, y_train = X_train[y_train == 0], y_train[y_train == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Data to DAGMM Model\n",
    "next points are different from original paper:\n",
    "- $\\lambda_2$ is set to 0.0001 (paper: 0.005)\n",
    "- Add small value($10^{-6}$) to diagonal elements of GMM covariance (paper: no additional value)\n",
    "\n",
    "Standard Scaler is applied to input data (This DAGMM implementation default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DAGMM(\n",
    "    comp_hiddens=[60, 30, 10, 1], comp_activation=tf.nn.tanh,\n",
    "    est_hiddens=[10, 4], est_dropout_ratio=0.5, est_activation=tf.nn.tanh,\n",
    "    learning_rate=0.0001, epoch_size=200, minibatch_size=1024, random_seed=1111\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 100/200 : loss = 80.526\n",
      " epoch 200/200 : loss = 72.563\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy thleshold to detect anomaly : 6.518\n"
     ]
    }
   ],
   "source": [
    "# Energy thleshold to detect anomaly = 80% percentile of energies\n",
    "anomaly_energy_threshold = np.percentile(y_pred, 80)\n",
    "print(f\"Energy thleshold to detect anomaly : {anomaly_energy_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies from test data\n",
    "y_pred_flag = np.where(y_pred >= anomaly_energy_threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precision = 0.932\n",
      " Recall    = 0.942\n",
      " F1-Score  = 0.937\n"
     ]
    }
   ],
   "source": [
    "prec, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred_flag, average=\"binary\")\n",
    "print(f\" Precision = {prec:.3f}\")\n",
    "print(f\" Recall    = {recall:.3f}\")\n",
    "print(f\" F1-Score  = {fscore:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
